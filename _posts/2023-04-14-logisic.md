Logistic Regression Classifier Tutoria
======================================
> 2020820017 김예진 6차 과제

# 1. 로지스틱 회귀란?
데이터 과학자가 새로운 분류 문제를 접할 때 가장 먼저 떠오를 수 있는 알고리즘은 로지스틱 회귀입니다.
이산 클래스 집합에 대한 관찰을 예측하는 데 사용되는 지도 학습 분류 알고리즘입니다. 
실제로 관측치를 여러 범주로 분류하는 데 사용됩니다. 따라서 출력은 본질적으로 이산적입니다. 
로지스틱 회귀는 로짓 회귀라고도 합니다. 
분류 문제를 해결하는 데 사용되는 가장 간단하고 직관적이며 다양한 분류 알고리즘 중 하나입니다.

# 2. 로지스틱 회귀 직관
통계에서 로지스틱 회귀 모델은 주로 분류 목적으로 사용되는 널리 사용되는 통계 모델입니다. 이는 일련의 관찰이 주어지면 로지스틱 회귀 알고리즘이 이러한 관찰을 두 개 이상의 이산 클래스로 분류하는 데 도움이 된다는 것을 의미합니다. 따라서 대상 변수는 본질적으로 이산적입니다.

로지스틱 회귀 알고리즘은 다음과 같이 작동합니다.
### 선형 방정식 구현
로지스틱 회귀 알고리즘은 응답 값을 예측하기 위해 독립 또는 설명 변수가 있는 선형 방정식을 구현하여 작동합니다. 예를 들어 공부한 시간과 시험에 합격할 확률의 예를 고려합니다. 여기서 학습시간은 설명변수로 x1로 표시한다. 시험에 합격할 확률은 응답 또는 목표 변수이며 z로 표시됩니다.
하나의 설명 변수(x1)와 하나의 응답 변수(z)가 있는 경우 선형 방정식은 수학적으로 다음 방정식으로 주어집니다.

    z = β0 + β1x1
    
여기서 계수 β0 및 β1은 모델의 매개변수입니다.

설명 변수가 여러 개인 경우 위의 방정식은 다음과 같이 확장될 수 있습니다

    z = β0 + β1x1+ β2x2+……..+ βnxn
    
여기서 계수 β0, β1, β2 및 βn은 모델의 매개변수입니다.

따라서 예측 응답 값은 위의 방정식으로 주어지며 z로 표시됩니다.

### Sigmoid 함수
z로 표시된 이 예측 응답 값은 0과 1 사이의 확률 값으로 변환됩니다. 예측 값을 확률 값에 매핑하기 위해 시그모이드 함수를 사용합니다. 그런 다음 이 시그모이드 함수는 모든 실제 값을 0과 1 사이의 확률 값으로 매핑합니다.

기계 학습에서 시그모이드 함수는 예측을 확률에 매핑하는 데 사용됩니다. 시그모이드 함수는 S자 모양의 곡선을 가집니다. 시그모이드 곡선이라고도 합니다.

Sigmoid 함수는 Logistic 함수의 특별한 경우입니다. 다음 수학 공식으로 제공됩니다.

그래픽으로 시그모이드 함수를 다음 그래프로 나타낼 수 있습니다.
