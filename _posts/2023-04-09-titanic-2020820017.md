타이타닉 관련 모델 훈련 과정
=========
2020820017 김예진 
----------------
"타이타닉 호에 탑승했던 사람들의 정보를 바탕으로 생존자를 예측하는 문제"
------------------------------------------------------
> **기본 설정**
```python
#파이썬 3.7 이상을 요구한다.
import sys
assert sys.version_info >= (3, 7)

#사이킷런 1.0.1 이상을 요구한다.
import sklearn
assert sklearn.__version__ >= "1.0.1"

#다음은 이미지에 포함된 폰트 크기를 설정한다.
import matplotlib.pyplot as plt

plt.rc('font', size=14)
plt.rc('axes', labelsize=14, titlesize=14)
plt.rc('legend', fontsize=14)
plt.rc('xtick', labelsize=10)
plt.rc('ytick', labelsize=10)
```

데이터를 가져와서 로드하는 과정입니다.
```python
from pathlib import Path
import pandas as pd
import tarfile
import urllib.request

def load_titanic_data():
    tarball_path = Path("datasets/titanic.tgz")
    if not tarball_path.is_file():
        Path("datasets").mkdir(parents=True, exist_ok=True)
        url = "https://github.com/ageron/data/raw/main/titanic.tgz"
        urllib.request.urlretrieve(url, tarball_path)
        with tarfile.open(tarball_path) as titanic_tarball:
            titanic_tarball.extractall(path="datasets")
    return [pd.read_csv(Path("datasets/titanic") / filename)
            for filename in ("train.csv", "test.csv")]
```
```python
train_data, test_data = load_titanic_data()
```
데이터는 이미 학습 세트와 테스트 세트로 분할되어 있습니다. 그러나 테스트 데이터에는 레이블이 포함되어 있지 않습니다. 목표는 훈련 데이터를 사용하여 가능한 최고의 모델을 훈련한 다음 테스트 데이터에 대한 예측을 만들고 Kaggle에 업로드하여 최종 점수를 확인하는 것입니다.
트레이닝 세트의 상위 몇 행을 살펴보겠습니다.
```python
train_data.head()
```
실행한 결과입니다.

<img width="1205" alt="스크린샷 2023-04-09 19 12 21" src="https://user-images.githubusercontent.com/130275704/230767011-e4108a85-b481-4096-aacc-b7d5dd700e28.png">
속성의 의미는 다음과 같습니다.
- PassengerId: 각 승객의 고유 식별자
- Survived: 그것이 목표입니다. 0은 승객이 생존하지 못했음을 의미하고 1은 생존을 의미합니다.
- Pclass: 여객 등급.
- Name, Sex, Age: 자명함
- SibSp: 타이타닉에 탑승한 승객의 형제 및 배우자 수
- Parch: 타이타닉에 탑승한 승객의 자녀 및 부모 수
- Ticket: 티켓 id
- Fare: 지불 가격(파운드)
- Cabin: 승객의 캐빈 번호
- Embarked: 승객이 타이타닉에 승선한 곳

목표는 승객의 연령, 성별, 승객 등급, 승선 장소 등과 같은 속성을 기반으로 승객의 생존 여부를 예측하는 것입니다.
PassengerId 열을 인덱스 열로 명시적으로 설정해 보겠습니다.
```python
train_data = train_data.set_index("PassengerId")
test_data = test_data.set_index("PassengerId")
```
누락된 데이터의 양을 확인하기 위해 더 많은 정보를 얻겠습니다.
```python
train_data.info()
```
실행한 결과입니다.

<img width="344" alt="스크린샷 2023-04-09 19 16 13" src="https://user-images.githubusercontent.com/130275704/230767144-b9ea9b37-a61e-4e05-98c0-5b1236c2b6cc.png">
```python
train_data[train_data["Sex"]=="female"]["Age"].median()
```
> 27.0

Age, Cabin 및 Embarked 속성은 때때로 null(891 미만의 null이 아님), 특히 Cabin(77%는 null)입니다. 지금은 Cabin을 무시하고 나머지에 집중하겠습니다. Age 속성에는 약 19%의 null 값이 있으므로 이를 어떻게 처리할지 결정해야 합니다. null 값을 평균 연령으로 바꾸는 것이 합리적으로 보입니다. 다른 열을 기반으로 연령을 예측하면 좀 더 똑똑해질 수 있지만(예를 들어 중앙 연령은 1등석 37세, 2등석 29세, 3등석 24세) 간단하게 유지하고 전체 평균 연령.

이름 및 티켓 특성에는 약간의 값이 있을 수 있지만 모델이 사용할 수 있는 유용한 숫자로 변환하기가 약간 까다로울 수 있습니다. 따라서 지금은 무시하겠습니다.

숫자 속성을 살펴보겠습니다.

```python
train_data.describe()
```
실행한 결과입니다.
<img width="584" alt="스크린샷 2023-04-09 19 18 22" src="https://user-images.githubusercontent.com/130275704/230767218-f318437b-abd3-4c62-967d-2a783508a022.png">
- 맙소사, 38%만 살아남았습니다! 40%에 가깝기 때문에 정확도는 우리 모델을 평가하는 합리적인 척도가 될 것입니다.
- 평균 요금은 32.20파운드로 그다지 비싸지 않은 것 같습니다(당시에는 아마 많은 돈이었을 것입니다).
- 평균 연령은 30세 미만이었다.

대상이 실제로 0 또는 1인지 확인합시다.
```python
train_data["Survived"].value_counts()
```
이제 모든 범주 속성을 간단히 살펴보겠습니다.

```python
train_data["Pclass"].value_counts()
```
```python
train_data["Sex"].value_counts()
```
```python
train_data["Embarked"].value_counts()
```
Embarked 속성은 승객이 승선한 위치를 알려줍니다. C=Cherbourg, Q=Queenstown, S=Southampton.

이제 숫자 속성에 대한 파이프라인부터 시작하여 전처리 파이프라인을 빌드해 보겠습니다.
```python
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

num_pipeline = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler())
])
```
이제 범주 속성에 대한 파이프라인을 구축할 수 있습니다.
```python
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder
```
```python
cat_pipeline = Pipeline([
        ("ordinal_encoder", OrdinalEncoder()),
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("cat_encoder", OneHotEncoder(sparse=False)),
    ])
```
마지막으로 수치 및 범주 파이프라인을 연결해 보겠습니다.
```python
from sklearn.compose import ColumnTransformer

num_attribs = ["Age", "SibSp", "Parch", "Fare"]
cat_attribs = ["Pclass", "Sex", "Embarked"]

preprocess_pipeline = ColumnTransformer([
        ("num", num_pipeline, num_attribs),
        ("cat", cat_pipeline, cat_attribs),
    ])
```
이제 우리는 원시 데이터를 가져오고 우리가 원하는 기계 학습 모델에 공급할 수 있는 숫자 입력 기능을 출력하는 멋진 전처리 파이프라인을 가지고 있습니다.
```python
X_train = preprocess_pipeline.fit_transform(train_data)
X_train
```
```python
y_train = train_data["Survived"]
```
이제 분류기를 훈련할 준비가 되었습니다. RandomForestClassifier부터 시작하겠습니다.
```python
forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)
forest_clf.fit(X_train, y_train)
```
좋습니다. 우리 모델이 훈련되었으니 이를 사용하여 테스트 세트에 대한 예측을 해봅시다.
```python
X_test = preprocess_pipeline.transform(test_data)
y_pred = forest_clf.predict(X_test)
```
그리고 이제 우리는 이러한 예측으로 CSV 파일을 빌드한 다음(Kaggle을 제외한 형식을 존중함) 업로드하고 최선을 다할 수 있습니다. 하지만 기다려! 우리는 희망보다 더 잘할 수 있습니다. 모델이 얼마나 좋은지 알아보기 위해 교차 검증을 사용하지 않는 이유는 무엇입니까?
```python
forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)
forest_scores.mean()
```
> 0.8137578027465668

Kaggler는 100% 정확도에 도달했지만 Titanic의 희생자 목록을 쉽게 찾을 수 있으므로 성능에 기계 학습이 거의 포함되지 않은 것 같습니다!
SVC를 사용해 봅시다.
```python
from sklearn.svm import SVC

svm_clf = SVC(gamma="auto")
svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)
svm_scores.mean()
```
> 0.8249313358302123

이 모델이 더 좋아 보입니다
ut 10개의 교차 검증 접기에서 평균 정확도를 보는 대신, 하한 및 상한 사분위수를 강조 표시하는 박스 플롯과 점수 범위를 보여주는 "수염"과 함께 각 모델에 대한 10개의 점수를 모두 플롯해 보겠습니다(감사합니다. 이 시각화를 제안한 Nevin Yilmaz에게). boxplot() 함수는 이상값("플라이어"라고 함)을 감지하고 수염에 포함하지 않습니다. 구체적으로, 하위 사분위수가 𝑄1이고 상위 사분위수가 𝑄3이면 사분위수 범위 𝐼𝑄𝑅=𝑄3−𝑄1(이것이 상자의 높이)이고 𝑄1−1.5×𝐼𝑄𝑅보다 낮은 점수는 플라이어이며 모든 점수도 마찬가지입니다. 𝑄3+1.5×𝐼𝑄𝑅 보다 큰 점수.

```python
plt.figure(figsize=(8, 4))
plt.plot([1]*10, svm_scores, ".")
plt.plot([2]*10, forest_scores, ".")
plt.boxplot([svm_scores, forest_scores], labels=("SVM", "Random Forest"))
plt.ylabel("Accuracy")
plt.show()
```
실행한 결과입니다.
<img width="621" alt="스크린샷 2023-04-09 19 28 44" src="https://user-images.githubusercontent.com/130275704/230767617-5db6b29d-2ad1-4345-ab6f-10e05f01afbf.png">
랜덤 포레스트 분류기는 10개의 접기 중 하나에서 매우 높은 점수를 받았지만 전반적으로 평균 점수가 낮고 산포도가 더 커서 SVM 분류기가 더 잘 일반화될 가능성이 있는 것으로 보입니다.

이 결과를 더 개선하려면 다음을 수행할 수 있습니다.
- 교차 검증 및 그리드 검색을 사용하여 더 많은 모델을 비교하고 하이퍼파라미터를 조정합니다.
- 예를 들어 더 많은 기능 엔지니어링을 수행하십시오.
  - 숫자 속성을 범주 속성으로 변환해 보십시오. 예를 들어, 연령 그룹마다 생존율이 매우 다르기 때문에(아래 참조) 연령 버킷 범주를 만들어 연령 대신 사용하는 것이 도움이 될 수 있습니다. 마찬가지로 혼자 여행하는 사람들 중 30%만이 살아남았기 때문에 혼자 여행하는 사람들을 위한 특별 범주가 있는 것이 유용할 수 있습니다(아래 참조).
  - SibSp와 Parch를 합계로 바꿉니다.
  - Survived 속성과 잘 연관되는 이름 부분을 식별하십시오.
  - 예를 들어 Cabin 열을 사용하여 첫 글자를 범주 속성으로 처리합니다.

```python
train_data["AgeBucket"] = train_data["Age"] // 15 * 15
train_data[["AgeBucket", "Survived"]].groupby(['AgeBucket']).mean()
```
<img width="182" alt="스크린샷 2023-04-09 19 30 26" src="https://user-images.githubusercontent.com/130275704/230767684-83ed6065-7a31-4780-bd9f-b7f22c0251b6.png">

```python
train_data["RelativesOnboard"] = train_data["SibSp"] + train_data["Parch"]
train_data[["RelativesOnboard", "Survived"]].groupby(
    ['RelativesOnboard']).mean()
```
<img width="240" alt="스크린샷 2023-04-09 19 31 04" src="https://user-images.githubusercontent.com/130275704/230767704-73b3f1a6-a4cd-4096-ac1e-ee7388aafbe9.png">


